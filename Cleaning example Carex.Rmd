---
title: "Data Cleaning Cyoeraceae Sweden"
author: "Charlie Campbell"
date: "19/10/2020"
bibliography: "./Bibliography/Bibliography.bib"
output: html_document
---
# Cyperaceeae of Sweden
In this example I have downloaded the occurances of the Cyperaceae family in Sweden from GBIF since 2000. This is a single data set from an area with an agreed taxonomy (dyntaxa.se). Our aim here is to take a group of records from GBIF and using Dyntaxa as a backbone clean the records to be in such a state as to be used for various things.

First we give each record in the assembled data set a unique ID. In this case it could be possible to use the GBIFid. In data sets sourced from mulitple sources it is a good idea to create a unique ID related to the data source.

```{r, warning=FALSE, error=FALSE, message=FALSE, error=FALSE, message=FALSE}
library(data.table)
library(dplyr)
library(ggplot2)
library(CoordinateCleaner)
library(kableExtra)
library(dismo)
library(sf)
library(ggplot2)
library(cowplot)
library(BIRDS)

Carex <- fread(list.files("./BDcleaner_Scripts/Example/Downloads/ignored data/cyperaceae/",
                          pattern = ".csv",
                          full.names = TRUE), encoding =  "UTF-8")

Carex$ID <- paste0("car-",1:nrow(Carex))
save(Carex ,file = "./BDcleaner_Scripts/Example/Downloads/ignored data/Cyperacea_SWE.data")
```

In cleaning data there are a number of dimensions of uncertainty we shall fir

## Taxonomy
In the species column there are records with no Species given in the species column. We then check the scientificName for whether there is useful information there
```{r , warning=FALSE, error=FALSE, message=FALSE}

kable(Carex %>%
  filter(species == "") %>%
  distinct(scientificName))%>%
   kable_styling(latex_options = c("striped", "hold_position"),
                full_width = F)

```
In this case there are only genre recorded.

We then check for data about species in the locality information for which there are no species data given in the species column. Here there are enough unique values to be checked easily within R. It is possible that in large data sets that there may be very many records for which there is useful information 

```{r , warning=FALSE, error=FALSE, message=FALSE}
kable(head(Carex %>%
  filter(species == "") %>%
  select(locality) %>%
  distinct())) %>%
   kable_styling(latex_options = c("striped", "hold_position"),
                full_width = F)
```

There are no species data in the locality field and so we begin a vector of IDs that are not at the required data resolution.
```{r, warning=FALSE, error=FALSE, message=FALSE }
unUseful <- Carex %>%
            filter(Carex$species == "")%>%
            .$ID

```


We now need to check that the species names in the records that we are using are valid for the area which we are looking at i.e. Sweden. There are several resources out there that do this (HERE I SUGGEST A LINK TO A WEBSITE LISTING LIBRARIES AND RESOURCES FOR THE VALIDITY OF NAMES). As we are looking specifically and solely at Sweden there is [Dyntaxa.se](https://www.dyntaxa.se/). There is also and R interface as part of the [Bioatlas of Sweden](https://github.com/bioatlas) github repository. For wider applicability we will export the unique names from the Carex data frame. These will then be copied to the [Dyntaxa portal](https://www.dyntaxa.se/Match/Settings/0) for matching multiple names. The results are checked against the Swedish lists and unknown species or uncertainties are flagged. Names can be copied directly into a box in Dyntaxa or may be imported directly as an xlsx file. Here we shall export just the species names. There are multiple options. 

```{r, warning=FALSE, error=FALSE, message=FALSE}
library(openxlsx)
SpeciesNames <- Carex %>%
  filter(!ID %in% unUseful)%>%
  select(species)%>%
  distinct()

#write.xlsx(SpeciesNames,"./BDcleaner_Scripts/Example/UniqueCarexTaxa.xlsx")

```
 Dyntaxa provides options for any taxononmic uncertainties and lists the species for which no match can be made. Having made selections it exports as a .xlslx file. We can then check what those species for which there is no information about what they are. In this case there are an number of species which are likely to be horticultural, a few taxa which are of hybrid origin which are in the Dyntaxa with the addition of 'Ã—' between genus and species, and *Carex utriculata* a species from North America. This last could be a misidentification of *C. rostrata*. We will exclude the horticultural and uncertain species. We do this by adding a **Species** column in the Dyntaxa file and then load that file into R. 

```{r, warning=FALSE, error=FALSE, message=FALSE}
library(openxlsx)
SpeciesNames <- read.xlsx("./BDcleaner_Scripts/Example/matchCarex.xlsx")

Carex <- merge(Carex, 
               SpeciesNames[,c("Provided.string","SpeciesDyn")],
               by.x = "species",by.y = "Provided.string",
               all.x = TRUE)
```
We then add IDs of the rows with taxa which are to be excluded to the unUseful vector. It is possible that there is overlap between these vectors. Rather than overwriting the vector we join the vectors together and use unique to get a vector with no duplications.
```{r, warning=FALSE, error=FALSE, message=FALSE}
unUseful <- unique( 
  c(unUseful,
  Carex %>%
  filter(is.na(SpeciesDyn)) %>%
  .$ID))
```

##Coordinate Cleaning

We need to extract locality data for rows where there is no lat/lon information to geocode it, producing a latitude and longitude for each locality. This can be carried out in a similar way as for species ie the merging of data frames. This can be also be done automatically in R using the geocode feature of the libraries tidygeocoder or ggmap. Some of these services require an API key (eg. google). See the documentation for the lin for more information
```{r, warning=FALSE, error=FALSE, message=FALSE}
Localities <- Carex %>%
              filter(is.na(decimalLongitude))%>%
              select(locality) %>%
              distinct()
write.csv(Localities,"./BDcleaner_Scripts/Example/Localities.csv",row.names = FALSE)
```

For brevity we will simply include the records with no lat/lon info in the unUseful vector. These will ultimately not be used.
```{r, warning=FALSE, error=FALSE, message=FALSE}
unUseful <- unique(c(unUseful,
                     Carex%>%
                       filter(is.na(decimalLatitude))%>%
                       .$ID))
```

We now have an index of records we can't use owing to incomplete taxonomy or incomplete location information. We save these before cleaning the coordinates.

```{r, warning=FALSE, error=FALSE, message=FALSE}

save(Carex, unUseful, file = "./BDcleaner_Scripts/Example/Downloads/ignored data/Cyperacea_SWE.data")
```

Before cleaning the coordinates we simplify the data retaining columns that have information directly related to the collection of the data.

```{r, warning=FALSE, error=FALSE, message=FALSE}
Carex <- Carex %>%
        select(SpeciesDyn,
               decimalLongitude,
               decimalLatitude,
               coordinateUncertaintyInMeters,
               locality,
               recordedBy,
               countryCode,
               eventDate,
               year,
               month,
               day,
               institutionCode,
               collectionCode,
               catalogNumber,
               ID)
```


We then filter out the data rows for which we can not use ie those of too great taxanomic uncertainty. The data may then be cleaned. 

There are a number of things to consider when cleaning data:

  * How precise are the locations? Coordinate uncertainty ranges in the Cyperaceae of Sweden from 1 m - 30.5 km.
  * Are interpreted coordinates sufficient? These interpreted coordinates may imply a greater precision than is necessarily true
  * Are the locations likely to be errors? Errors can relate to where a sample is (eg herbarium location) rather than where it came from.
  * Are the locations in the country claimed? This can arrise through swapping of lat and lon; duplication of latitude numbers in the longitude; or simply incorrect coordinates being given.


```{r}
unUseful<-unique( c( unUseful,Carex %>%
              filter(is.na(coordinateUncertaintyInMeters)) %>%
              .$ID))
kable( t(table( round( Carex$coordinateUncertaintyInMeters, -2))))

```
We shall filter out all records with unknown coordinate uncertainty and all with a coordinate uncertainty more than 12.5 km.


```{r, warning=FALSE, error=FALSE, message=FALSE}

unUseful <- unique( c(unUseful, Carex %>%
  filter(is.na(coordinateUncertaintyInMeters))%>%
  .$ID))
unUseful <- unique( c(unUseful, Carex %>%
  filter(coordinateUncertaintyInMeters>12500)%>%
  .$ID))

```

We first remove the already labeled inaccurate data. We  then use the library CoordinateCleaner to automatically flag coordinates that may be errors. Outputs of this can be a cleaned dataframe or additional columns with doubtful records flagged. 
```{r,warning=FALSE, error=FALSE, message=FALSE}
Carex$countryCode <- countrycode::countrycode(Carex$countryCode,"iso2c","iso3c") #converts ISO2 country codes to ISO3

Carex <- Carex %>%
          filter(!ID %in% unUseful)


Carex <- clean_coordinates(Carex,
                  lon = "decimalLongitude",
                  lat = "decimalLatitude",
                  species = "SpeciesDyn",
                  countries = "countryCode",
                  tests = c("capitals", "centroids", "equal", "gbif", "institutions", "outliers", "seas", "zeros","countries")
                  )

kable( Carex%>%
  summarise(`Invalid coords` = sum(.val==FALSE),
            `Equal coords` = sum(.equ==FALSE),
            `0 coords` = sum(.zer==FALSE),
            `capitals` = sum(.cap==FALSE),
            `country centre` = sum(.cen==FALSE),
            `Country Border` = sum(.con==FALSE),
            `outlier` = sum(.otl==FALSE),
            `Gbif HQ` = sum(.gbf==FALSE),
            `Insitution` = sum(.inst==FALSE),
            `Summary` = sum(.summary==FALSE)), col.names = c("Invalid coords","Equal coords","0 coords","capitals", "country centre","Country Border","outlier","Gbif HQ","Insitution", "Summary"))
```

```{r, warning=FALSE, error=FALSE, message=FALSE}
kable(Carex %>%
  group_by(SpeciesDyn) %>%

  summarise(`Invalid coords` = sum(.val==FALSE),
            `Equal coords` = sum(.equ==FALSE),
            `0 coords` = sum(.zer==FALSE),
            `capitals` = sum(.cap==FALSE),
            `country centre` = sum(.cen==FALSE),
            `Country Border` = sum(.con==FALSE),
            `outlier` = sum(.otl==FALSE),
            `Gbif HQ` = sum(.gbf==FALSE),
            `Insitution` = sum(.inst==FALSE),
            `Summary` = sum(.summary==FALSE)))%>%
    kable_styling() %>%
  scroll_box(height = "300px")
```
Checking the

```{r, warning=FALSE, error=FALSE, message=FALSE}

Sweden <- getData("GADM",
                  country = "SWE",
                  level = 0)
Sweden_sf <- st_as_sf(Sweden)

BolMar <- ggplot(Sweden_sf)+
  geom_sf()+
  geom_point(data = Carex %>%
                filter(SpeciesDyn == "Carex capillaris") %>%
                 filter(.con == FALSE),
             aes(x = decimalLongitude,
                 y = decimalLatitude))+
  theme_cowplot()+
  ggtitle("Bolboschoenus maritimus")

CarAct <- ggplot(Sweden_sf)+
  geom_sf()+
  geom_point(data = Carex %>%
              filter(SpeciesDyn == "Bolboschoenus maritimus") %>%
                 filter(.otl == TRUE),
             aes(x = decimalLongitude,
                 y = decimalLatitude,
                 colour = .otl))+
  theme_cowplot()+
  ggtitle("Carex acuta")


```



I think some form of leaflet plot would be great here so that it is interactive
```{r, warning=FALSE, error=FALSE, message=FALSE}



Sweden <- getData("GADM",
                  country = "SWE",
                  level = 0)
grid_Sweden <- makeGrid(Sweden,25)

oB <- organiseBirds(Carex,sppCol = "SpeciesDyn")

SB <- summariseBirds(oB, grid_Sweden)
grid_Sweden <- st_as_sf(grid_Sweden)
Sweden <- st_as_sf(Sweden)

print(ggplot(grid_Sweden)+
  geom_sf()+
  geom_point(data = Carex, 
        
       aes(x = decimalLongitude,
           y = decimalLatitude)))

```

```{r, warning=FALSE, error=FALSE, message=FALSE}
SB_SPat <- st_as_sf(SB$spatial)

nSpecies <- ggplot(data = SB_SPat,aes(fill = nSpp))+
  geom_sf()+
  theme_cowplot()+
  scale_fill_gradientn(colors = matlab.like2(100))

nVisits <- ggplot(data = SB_SPat,aes(fill = nVis))+
  geom_sf()+
  theme_cowplot()+
  scale_fill_gradientn(colors = matlab.like2(100))

nObs <- ggplot(data = SB_SPat,aes(fill = nObs))+
  geom_sf()+
  theme_cowplot()+
  scale_fill_gradientn(colors = matlab.like2(100))

plot_grid(nSpecies, nVisits, nObs, ncol = 3)
```

